x[i] <- dados[indElementosEmbaralhados[i],]
}
warnings()
View(x)
library("RSNNS")
dados <- read.csv(file = "classificado3.csv",sep = ",")
dados$X <- NULL
N <- dim(dados)[1]
indElementosEmbaralhados <- sample(N)
x <-
for(i in 1:N){
x[i,] <- dados[indElementosEmbaralhados[i],]
}
library("RSNNS")
dados <- read.csv(file = "classificado3.csv",sep = ",")
dados$X <- NULL
N <- dim(dados)[1]
indElementosEmbaralhados <- sample(N)
x <- NULL
for(i in 1:N){
x[i,] <- dados[indElementosEmbaralhados[i],]
}
library("RSNNS")
dados <- read.csv(file = "classificado3.csv",sep = ",")
dados$X <- NULL
N <- dim(dados)[1]
indElementosEmbaralhados <- sample(N)
x <- data.frame(dados[,1],dados[,2],dados[,3],dados[4])
for(i in 1:N){
x[i,] <- dados[indElementosEmbaralhados[i],]
}
View(dados)
View(x)
treinamento <- x[1:81,]
View(treinamento)
library("RSNNS")
dados <- read.csv(file = "classificado3.csv",sep = ",")
dados$X <- NULL
N <- dim(dados)[1]
indElementosEmbaralhados <- sample(N)
x <- data.frame(dados[,1],dados[,2],dados[,3],dados[4])
for(i in 1:N){
x[i,] <- dados[indElementosEmbaralhados[i],]
}
treinamentoX <- x[1:81,1:3]
treinamentoY <- x[1:81,4]
View(treinamentoX)
View(x)
View(dados)
#configuracoes da MLP
nNeuronios = 10
maxEpocas <- 20000
#treinamento da MLP
redeCA <- NULL
#Backpropagation
print("treinando a rede na serie ajustada...")
redeCA<-mlp(treinamentoX, treinamentoY, size=nNeuronios, maxit=maxEpocas, initFunc="Randomize_Weights",
initFuncParams=c(-0.3, 0.3), learnFunc="Std_Backpropagation",
learnFuncParams=c(0.1), updateFunc="Topological_Order",
updateFuncParams=c(0), hiddenActFunc="Act_Logistic",
shufflePatterns=F, linOut=TRUE)
#PLOT DO ERRO
plot(redeCA$IterativeFitError,type="l",main="Erro da MLP CA")
primeiraClassificacaoX <- x[82:108]
primeiraClassificacaoX <- x[82:108,]
library("RSNNS")
dados <- read.csv(file = "classificado3.csv",sep = ",")
dados$X <- NULL
N <- dim(dados)[1]
indElementosEmbaralhados <- sample(N)
x <- data.frame(dados[,1],dados[,2],dados[,3],dados[4])
for(i in 1:N){
x[i,] <- dados[indElementosEmbaralhados[i],]
}
treinamentoX <- x[1:81,1:3]#60% da amostra
treinamentoY <- x[1:81,4]#60% da amostra
primeiraClassificacaoX <- x[82:108,1:3]
primeiraClassificacaoY <- x[82:108,4]
#configuracoes da MLP
nNeuronios = 10
maxEpocas <- 20000
#treinamento da MLP com 60% da amostra
redeCA <- NULL
#Backpropagation
print("treinando a rede na serie ajustada...")
redeCA<-mlp(treinamentoX, treinamentoY, size=nNeuronios, maxit=maxEpocas, initFunc="Randomize_Weights",
initFuncParams=c(-0.3, 0.3), learnFunc="Std_Backpropagation",
learnFuncParams=c(0.1), updateFunc="Topological_Order",
updateFuncParams=c(0), hiddenActFunc="Act_Logistic",
shufflePatterns=F, linOut=TRUE)
#PLOT DO ERRO
plot(redeCA$IterativeFitError,type="l",main="Erro da MLP CA")
#primeira classificação com 20% da amostra
yhat <- predict(redeCA,primeiraClassificacaoX)
library("RSNNS")
dados <- read.csv(file = "classificado3.csv",sep = ",")
N <- dim(dados)[1]
indElementosEmbaralhados <- sample(N)
x <- data.frame(dados[,2],dados[,3],dados[,4],dados[5])
for(i in 1:N){
x[i,] <- dados[indElementosEmbaralhados[i],]
}
treinamentoX <- x[1:81,2:4]#60% da amostra
treinamentoY <- x[1:81,5]#60% da amostra
primeiraClassificacaoX <- x[82:108,2:4]
primeiraClassificacaoY <- x[82:108,5]
#configuracoes da MLP
nNeuronios = 10
maxEpocas <- 20000
#treinamento da MLP com 60% da amostra
redeCA <- NULL
#Backpropagation
print("treinando a rede na serie ajustada...")
redeCA<-mlp(treinamentoX, treinamentoY, size=nNeuronios, maxit=maxEpocas, initFunc="Randomize_Weights",
initFuncParams=c(-0.3, 0.3), learnFunc="Std_Backpropagation",
learnFuncParams=c(0.1), updateFunc="Topological_Order",
updateFuncParams=c(0), hiddenActFunc="Act_Logistic",
shufflePatterns=F, linOut=TRUE)
#PLOT DO ERRO
plot(redeCA$IterativeFitError,type="l",main="Erro da MLP CA")
library("RSNNS")
dados <- read.csv(file = "classificado3.csv",sep = ",")
N <- dim(dados)[1]
indElementosEmbaralhados <- sample(N)
x <- data.frame(dados[,2],dados[,3],dados[,4],dados[5])
View(dados)
View(x)
for(i in 1:N){
x[i,] <- dados[indElementosEmbaralhados[i],]
}
View(x)
library("RSNNS")
dados <- read.csv(file = "classificado3.csv",sep = ",")
N <- dim(dados)[1]
indElementosEmbaralhados <- sample(N)
x <- data.frame(dados[,1],dados[,2],dados[,3],dados[,4],dados[5])
for(i in 1:N){
x[i,] <- dados[indElementosEmbaralhados[i],]
}
View(dados)
View(x)
treinamentoX <- x[1:81,2:4]#60% da amostra
treinamentoY <- x[1:81,5]#60% da amostra
View(treinamentoX)
primeiraClassificacaoX <- x[82:108,2:4]
primeiraClassificacaoY <- x[82:108,5]
#configuracoes da MLP
nNeuronios = 10
maxEpocas <- 20000
#treinamento da MLP com 60% da amostra
redeCA <- NULL
#Backpropagation
print("treinando a rede na serie ajustada...")
redeCA<-mlp(treinamentoX, treinamentoY, size=nNeuronios, maxit=maxEpocas, initFunc="Randomize_Weights",
initFuncParams=c(-0.3, 0.3), learnFunc="Std_Backpropagation",
learnFuncParams=c(0.1), updateFunc="Topological_Order",
updateFuncParams=c(0), hiddenActFunc="Act_Logistic",
shufflePatterns=F, linOut=TRUE)
#PLOT DO ERRO
plot(redeCA$IterativeFitError,type="l",main="Erro da MLP CA")
#primeira classificação com 20% da amostra
yhat <- predict(redeCA,primeiraClassificacaoX)
plot(x[82:108,1],primeiraClassificacaoY,type="l",col="blue",xlab="",ylab="")
plot(x[82:108,1],primeiraClassificacaoY,type="c",col="blue",xlab="",ylab="")
confusao <- confusion.matrix(tail(primeiraClassificacaoY,27),yhat)
print(confusao)
#usada para gerar matrix de confusao
library(SDMTools)
install.packages("SDMTools")
#usada para gerar matrix de confusao
library(SDMTools)
#gera a matrix de confusao
confusao <- confusion.matrix(tail(primeiraClassificacaoY,27),yhat)
#padroniza
padroniza <- function(s)
{
retorno <- (s - min(s))/(max(s)-min(s))
return(retorno)
}
#gera a matrix de confusao
confusao <- confusion.matrix(tailpadroniza((primeiraClassificacaoY),27),padroniza(yhat))
#gera a matrix de confusao
confusao <- confusion.matrix(tail(padroniza(primeiraClassificacaoY),27),padroniza(yhat))
padroniza(primeiraClassificacaoY)
padroniza(yhat)
yhat
padroniza(yhat)
confusao <- confusion.matrix(tail(padroniza(primeiraClassificacaoY),27),padroniza(yhat))
library("RSNNS")
#usada para gerar matrix de confusao
library(SDMTools)
dados <- read.csv(file = "classificado3.csv",sep = ",")
N <- dim(dados)[1]
indElementosEmbaralhados <- sample(N)
x <- data.frame(dados[,1],dados[,2],dados[,3],dados[,4],dados[5])
for(i in 1:N){
x[i,] <- dados[indElementosEmbaralhados[i],]
}
treinamentoX <- x[1:81,2:4]#60% da amostra
treinamentoY <- x[1:81,5]#60% da amostra
primeiraClassificacaoX <- x[82:108,2:4]
primeiraClassificacaoY <- x[82:108,5]
#configuracoes da MLP
nNeuronios = 10
maxEpocas <- 20000
#treinamento da MLP com 60% da amostra
redeCA <- NULL
#Backpropagation
print("treinando a rede na serie ajustada...")
redeCA<-mlp(treinamentoX, treinamentoY, size=nNeuronios, maxit=maxEpocas, initFunc="Randomize_Weights",
initFuncParams=c(-0.3, 0.3), learnFunc="Std_Backpropagation",
learnFuncParams=c(0.1), updateFunc="Topological_Order",
updateFuncParams=c(0), hiddenActFunc="Act_Logistic",
shufflePatterns=F, linOut=TRUE)
#PLOT DO ERRO
plot(redeCA$IterativeFitError,type="l",main="Erro da MLP CA")
#primeira classificação com 20% da amostra
yhat <- predict(redeCA,primeiraClassificacaoX)
barplot(resultado, names.arg = c("0-0","0-1","1-1","1-0"),col = c("green","red","green","red"),xlab="Previsoes",ylab="Quantidade")
plot(redeCA$IterativeFitError,type="l",main="Erro da MLP CA")
yhat.size
yhat
yhat.size()
size(yhat)
length(yhat)
padroniza_em_grupos <- function(vet){
if(vet[i] <= 1 || (vet[i] >= 1 && vet[i] < 1.5)){
vet[i] <- 1
}else if(((vet[i] >= 1.5) && (x <= 2)) || ((vet[i] >= 2) && (vet[i] <= 2.5))){
vet[i] <- 2
}else{
vet[i] <- 3
}
}
padroniza_em_grupos <- function(vet){
if(vet[i] <= 1 || (vet[i] >= 1 && vet[i] < 1.5)){
vet[i] <- 1
}else if(((vet[i] >= 1.5) && (x <= 2)) || ((vet[i] >= 2) && (vet[i] <= 2.5))){
vet[i] <- 2
}else{
vet[i] <- 3
}
return(vet)
}
teste <- padroniza_em_grupos(yhat)
padroniza_em_grupos <- function(vet){
for(i in 1:length(vet)){
if(vet[i] <= 1 || (vet[i] >= 1 && vet[i] < 1.5)){
vet[i] <- 1
}else if(((vet[i] >= 1.5) && (x <= 2)) || ((vet[i] >= 2) && (vet[i] <= 2.5))){
vet[i] <- 2
}else{
vet[i] <- 3
}
}
return(vet)
}
teste <- padroniza_em_grupos(yhat)
yhat
teste2 <- data.frame(yhat,teste)
View(teste2)
padroniza_em_grupos <- function(vet){
for(i in 1:length(vet)){
if(vet[i] <= 1 || (vet[i] >= 1 && vet[i] < 1.5)){
vet[i] <- 1
}else if(((vet[i] >= 1.5) && (x <= 2)) || ((vet[i] >= 2) && (vet[i] <= 2.5)))){
vet[i] <- 2
}else{
vet[i] <- 3
}
}
return(vet)
}
padroniza_em_grupos <- function(vet){
for(i in 1:length(vet)){
if(vet[i] <= 1 || (vet[i] >= 1 && vet[i] < 1.5)){
vet[i] <- 1
}else if((vet[i] >= 1.5 && x <= 2) || (vet[i] >= 2 && vet[i] <= 2.5)){
vet[i] <- 2
}else{
vet[i] <- 3
}
}
return(vet)
}
teste <- padroniza_em_grupos(yhat)
teste2 <- data.frame(yhat,teste)
padroniza_em_grupos <- function(vet){
for(i in 1:length(vet)){
if(vet[i] <= 1 || (vet[i] >= 1 && vet[i] < 1.5)){
vet[i] <- 1
}else if(((vet[i] >= 1.5) && (vet[i] <= 2)) || ((vet[i] >= 2) && (vet[i] <= 2.5))){
vet[i] <- 2
}else{
vet[i] <- 3
}
}
return(vet)
}
teste <- padroniza_em_grupos(yhat)
teste2 <- data.frame(yhat,teste)
library("RSNNS")
#usada para gerar matrix de confusao
library(SDMTools)
dados <- read.csv(file = "classificado3.csv",sep = ",")
N <- dim(dados)[1]
indElementosEmbaralhados <- sample(N)
x <- data.frame(dados[,1],dados[,2],dados[,3],dados[,4],dados[5])
for(i in 1:N){
x[i,] <- dados[indElementosEmbaralhados[i],]
}
treinamentoX <- x[1:81,2:4]#60% da amostra
treinamentoY <- x[1:81,5]#60% da amostra
primeiraClassificacaoX <- x[82:108,2:4]
primeiraClassificacaoY <- x[82:108,5]
#configuracoes da MLP
nNeuronios = 10
maxEpocas <- 20000
#treinamento da MLP com 60% da amostra
redeCA <- NULL
#Backpropagation
print("treinando a rede na serie ajustada...")
redeCA<-mlp(treinamentoX, treinamentoY, size=nNeuronios, maxit=maxEpocas, initFunc="Randomize_Weights",
initFuncParams=c(-0.3, 0.3), learnFunc="Std_Backpropagation",
learnFuncParams=c(0.1), updateFunc="Topological_Order",
updateFuncParams=c(0), hiddenActFunc="Act_Logistic",
shufflePatterns=F, linOut=TRUE)
#PLOT DO ERRO
plot(redeCA$IterativeFitError,type="l",main="Erro da MLP CA")
#primeira classificação com 20% da amostra
yhat <- predict(redeCA,primeiraClassificacaoX)
padroniza_em_grupos <- function(vet){
for(i in 1:length(vet)){
if(vet[i] <= 1 || (vet[i] >= 1 && vet[i] < 1.5)){
vet[i] <- 1
}else if(((vet[i] >= 1.5) && (vet[i] <= 2)) || ((vet[i] >= 2) && (vet[i] <= 2.5))){
vet[i] <- 2
}else{
vet[i] <- 3
}
}
return(vet)
}
yhatPadronizado <- padroniza_em_grupos(yhat)
conta_grupos <- function(vet){
qtd1 <- 0
qtd2 <- 0
qtd3 <- 0
for(i in 1:length(vet)){
if(vet[i] == 1){
qtd1 <- qtd1 + 1
}else if(vet[i] == 2){
qtd2 <- qtd2 + 1
}else{
qtd3 <- qtd3 + 1
}
}
return(c(qtd1,qtd2,qtd3))
}
teste <- conta_grupos(y)
teste <- conta_grupos(primeiraClassificacaoY)
barplot(teste, main="Classificação de grupos",
xlab="Number of Gears")
barplot(teste, main="Classificação de grupos",
xlab="Number of Gears", names.arg=c("3 Gears", "4 Gears", "5 Gears"))
barplot(teste, main="Classificação de grupos",
xlab="Number of Gears", names.arg=c("Grupo 1", "Grupo 2", "Grupo 3"))
barplot(teste, main="Classificação de grupos",
xlab="Number of Gears", names.arg=c("Grupo 1", "Grupo 2", "Grupo 3"),ylab = "quantidade")
barplot(teste, main="Classificação de grupos",
xlab="Grupos", names.arg=c("Grupo 1", "Grupo 2", "Grupo 3"),ylab = "Quantidade")
barplot(teste, main="Classificação de grupos",
xlab="Grupos", names.arg=c("Grupo 1", "Grupo 2", "Grupo 3"),ylab = "Quantidade", col = c("red","green","blue"))
barplot(teste, main="Classificação de grupos",
xlab="Grupos", names.arg=c("Grupo 1", "Grupo 2", "Grupo 3"),
ylab = "Quantidade", col = c("red","green","blue"))
teste <- conta_grupos(yhat)
barplot(teste, main="Classificação de grupos",
xlab="Grupos", names.arg=c("Grupo 1", "Grupo 2", "Grupo 3"),
ylab = "Quantidade", col = c("red","green","blue"))
teste <- conta_grupos(yhatPadronizado)
barplot(teste, main="Classificação de grupos",
xlab="Grupos", names.arg=c("Grupo 1", "Grupo 2", "Grupo 3"),
ylab = "Quantidade", col = c("red","green","blue"))
teste <- conta_grupos(primeiraClassificacaoY)
barplot(teste, main="Classificação de grupos",
xlab="Grupos", names.arg=c("Grupo 1", "Grupo 2", "Grupo 3"),
ylab = "Quantidade", col = c("red","green","blue"))
plot(redeCA$IterativeFitError,type="l",main="Erro da MLP CA")
barplot(teste, main="Classificação de grupos",
xlab="Grupos", names.arg=c("Grupo 1", "Grupo 2", "Grupo 3"),
ylab = "Quantidade", col = c("red","green","blue"))
library("RSNNS")
#usada para gerar matrix de confusao
library(SDMTools)
dados <- read.csv(file = "classificado3.csv",sep = ",")
N <- dim(dados)[1]
indElementosEmbaralhados <- sample(N)
x <- data.frame(dados[,1],dados[,2],dados[,3],dados[,4],dados[5])
for(i in 1:N){
x[i,] <- dados[indElementosEmbaralhados[i],]
}
treinamentoX <- x[1:81,2:4]#60% da amostra
treinamentoY <- x[1:81,5]#60% da amostra
primeiraClassificacaoX <- x[82:135,2:4]
primeiraClassificacaoY <- x[82:135,5]
#configuracoes da MLP
nNeuronios = 10
maxEpocas <- 20000
#treinamento da MLP com 60% da amostra
redeCA <- NULL
#Backpropagation
print("treinando a rede na serie ajustada...")
redeCA<-mlp(treinamentoX, treinamentoY, size=nNeuronios, maxit=maxEpocas, initFunc="Randomize_Weights",
initFuncParams=c(-0.3, 0.3), learnFunc="Std_Backpropagation",
learnFuncParams=c(0.1), updateFunc="Topological_Order",
updateFuncParams=c(0), hiddenActFunc="Act_Logistic",
shufflePatterns=F, linOut=TRUE)
#PLOT DO ERRO
plot(redeCA$IterativeFitError,type="l",main="Erro da MLP CA")
#primeira classificação com 20% da amostra
yhat <- predict(redeCA,primeiraClassificacaoX)
padroniza_em_grupos <- function(vet){
for(i in 1:length(vet)){
if(vet[i] <= 1 || (vet[i] >= 1 && vet[i] < 1.5)){
vet[i] <- 1
}else if(((vet[i] >= 1.5) && (vet[i] <= 2)) || ((vet[i] >= 2) && (vet[i] <= 2.5))){
vet[i] <- 2
}else{
vet[i] <- 3
}
}
return(vet)
}
yhatPadronizado <- padroniza_em_grupos(yhat)
conta_grupos <- function(vet){
qtd1 <- 0
qtd2 <- 0
qtd3 <- 0
for(i in 1:length(vet)){
if(vet[i] == 1){
qtd1 <- qtd1 + 1
}else if(vet[i] == 2){
qtd2 <- qtd2 + 1
}else{
qtd3 <- qtd3 + 1
}
}
return(c(qtd1,qtd2,qtd3))
}
teste <- conta_grupos(primeiraClassificacaoY)
barplot(teste, main="Classificação de grupos",
xlab="Grupos", names.arg=c("Grupo 1", "Grupo 2", "Grupo 3"),
ylab = "Quantidade", col = c("red","green","blue"))
teste <- conta_grupos(yhatPadronizado)
barplot(teste, main="Classificação de grupos",
xlab="Grupos", names.arg=c("Grupo 1", "Grupo 2", "Grupo 3"),
ylab = "Quantidade", col = c("red","green","blue"))
teste <- conta_grupos(primeiraClassificacaoY)
barplot(teste, main="Classificação de grupos",
xlab="Grupos", names.arg=c("Grupo 1", "Grupo 2", "Grupo 3"),
ylab = "Quantidade", col = c("red","green","blue"))
teste <- conta_grupos(yhatPadronizado)
barplot(teste, main="Classificação de grupos",
xlab="Grupos", names.arg=c("Grupo 1", "Grupo 2", "Grupo 3"),
ylab = "Quantidade", col = c("red","green","blue"))
teste <- conta_grupos(primeiraClassificacaoY)
barplot(teste, main="Classificação de grupos",
xlab="Grupos", names.arg=c("Grupo 1", "Grupo 2", "Grupo 3"),
ylab = "Quantidade", col = c("red","green","blue"))
teste <- conta_grupos(yhatPadronizado)
teste1 <- conta_grupos(primeiraClassificacaoY)
barplot(teste1, main="Classificação de grupos",
xlab="Grupos", names.arg=c("Grupo 1", "Grupo 2", "Grupo 3"),
ylab = "Quantidade", col = c("red","green","blue"))
teste2 <- conta_grupos(yhatPadronizado)
barplot(teste2, main="Classificação de grupos",
xlab="Grupos", names.arg=c("Grupo 1", "Grupo 2", "Grupo 3"),
ylab = "Quantidade", col = c("red","green","blue"))
teste
teste2
teste1 <- conta_grupos(primeiraClassificacaoY)
barplot(teste1, main="Classificação de grupos",
xlab="Grupos", names.arg=c("Grupo 1", "Grupo 2", "Grupo 3"),
ylab = "Quantidade", col = c("red","green","blue"))
teste2 <- conta_grupos(yhatPadronizado)
barplot(teste2, main="Classificação de grupos",
xlab="Grupos", names.arg=c("Grupo 1", "Grupo 2", "Grupo 3"),
ylab = "Quantidade", col = c("red","green","blue"))
teste1
teste2
print("qtd1","qtd2","qtd3")
print("qtd1"+"qtd2"+"qtd3")
paste("qtd1" , "qtd2","qtd3")
paste("qtd1" , "qtd2","qtd3","\n","oi")
teste1
teste2
teste1 <- conta_grupos(primeiraClassificacaoY)
barplot(teste1, main="Classificação de grupos para Y",
xlab="Grupos", names.arg=c("Grupo 1", "Grupo 2", "Grupo 3"),
ylab = "Quantidade", col = c("red","green","blue"))
teste2 <- conta_grupos(yhatPadronizado)
barplot(teste2, main="Classificação de grupos para Yhat",
xlab="Grupos", names.arg=c("Grupo 1", "Grupo 2", "Grupo 3"),
ylab = "Quantidade", col = c("red","green","blue"))
barplot(teste1, main="Classificação de grupos para Y",
xlab="Grupos", names.arg=c("Grupo 1", "Grupo 2", "Grupo 3"),
ylab = "Quantidade", col = c("red","green","blue"))
teste2 <- conta_grupos(yhatPadronizado)
barplot(teste2, main="Classificação de grupos para Yhat",
xlab="Grupos", names.arg=c("Grupo 1", "Grupo 2", "Grupo 3"),
ylab = "Quantidade", col = c("red","green","blue"))
